{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Text Classification\n",
        "\n",
        "###Demo 1: Calclulating Cosine Similarity Using Word2Vec\n",
        "### Run the following program on Jupyter notebook"
      ],
      "metadata": {
        "id": "tIce2sNDkH-b"
      },
      "id": "tIce2sNDkH-b"
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Install nltk and gensim library"
      ],
      "metadata": {
        "id": "CjI9LNQjkSH9"
      },
      "id": "CjI9LNQjkSH9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d55de2dd",
      "metadata": {
        "id": "d55de2dd",
        "outputId": "76123b96-e1e6-45b6-e4b2-508d895ca7bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (3.6.1)\n",
            "Requirement already satisfied: regex in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (from nltk) (2021.4.4)\n",
            "Requirement already satisfied: joblib in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
            "Requirement already satisfied: tqdm in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
            "Requirement already satisfied: click in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: gensim in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (4.2.0)\n",
            "Requirement already satisfied: Cython==0.29.28 in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
            "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\nameet mankar\\anaconda3\\lib\\site-packages (from gensim) (1.22.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libraries"
      ],
      "metadata": {
        "id": "-SipgBm6kZsY"
      },
      "id": "-SipgBm6kZsY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e707b49",
      "metadata": {
        "id": "8e707b49",
        "outputId": "2824e100-cd91-4623-b956-9b756eca86e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity between 'alice' and 'wonderland' - CBOW :  0.9568985\n",
            "Cosine similarity between 'alice' and 'machines' - CBOW :  0.8755512\n",
            "Cosine similarity between 'alice' and 'wonderland' - Skip Gram :  0.6938278\n",
            "Cosine similarity between 'alice' and 'machines' - Skip Gram :  0.82360184\n"
          ]
        }
      ],
      "source": [
        "# Python program to generate word vectors using Word2Vec\n",
        " \n",
        "# importing all necessary modules\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        " \n",
        "warnings.filterwarnings(action = 'ignore')\n",
        " \n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        " \n",
        "#  Reads ‘alice.txt’ file\n",
        "# Please provide the path of file from your system \n",
        "sample = open(r\"C:\\Users\\Nameet Mankar\\Documents\\Edureka\\alice.txt\",encoding=\"utf8\")\n",
        "s = sample.read()\n",
        " \n",
        "# Replaces escape character with space\n",
        "f = s.replace(\"\\n\", \" \")\n",
        " \n",
        "data = []\n",
        " \n",
        "# iterate through each sentence in the file\n",
        "for i in sent_tokenize(f):\n",
        "    temp = []\n",
        "     \n",
        "    # tokenize the sentence into words\n",
        "    for j in word_tokenize(i):\n",
        "        temp.append(j.lower())\n",
        " \n",
        "    data.append(temp)\n",
        " \n",
        "\n",
        "#Create CBOW model\n",
        "model1 = gensim.models.Word2Vec(data, min_count = 1,vector_size = 100, window = 5)\n",
        " \n",
        "# Print results\n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - CBOW : \",model1.wv.similarity('alice', 'wonderland'))\n",
        "     \n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'machines' - CBOW : \",model1.wv.similarity('alice', 'machines'))\n",
        " \n",
        "# Create Skip Gram model\n",
        "model2 = gensim.models.Word2Vec(data, min_count = 1, vector_size = 100,window = 5, sg = 1)\n",
        " \n",
        "# Print results\n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'wonderland' - Skip Gram : \",model2.wv.similarity('alice', 'wonderland'))\n",
        "     \n",
        "print(\"Cosine similarity between 'alice' \" + \"and 'machines' - Skip Gram : \", model2.wv.similarity('alice', 'machines'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea70060f",
      "metadata": {
        "id": "ea70060f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Cosine Similarity with Word2Vec.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}